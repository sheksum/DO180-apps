import requests
from requests.adapters import HTTPAdapter
from urllib3.util import Retry
import json

# Configuration: set your NetBox URL and the API endpoint or prefix ID
BASE_URL   = "http://netbox.example.com"       # NetBox server URL (no trailing slash)
API_TOKEN  = "YOUR_NETBOX_API_TOKEN"           # NetBox API token for authentication
ENDPOINT   = "/api/ipam/prefixes/50983/"       # Example endpoint (specific prefix ID or just "/api/ipam/prefixes/")

# Prepare the full URL and HTTP headers
url = BASE_URL + ENDPOINT  # full URL to request
headers = {
    "Accept": "application/json",
    "Authorization": f"Token {API_TOKEN}"
}

# Set up a Session with retry logic for robust requests
session = requests.Session()
retry_strategy = Retry(
    total=5,                    # total retry attempts
    backoff_factor=1,           # wait 1 second * (2 ^ (retry count - 1)) between retries
    status_forcelist=[429, 500, 502, 503, 504],  # HTTP statuses to retry on
    allowed_methods=["GET", "HEAD", "OPTIONS"]   # methods to apply retries to
)
adapter = HTTPAdapter(max_retries=retry_strategy)
session.mount("http://", adapter)
session.mount("https://", adapter)

all_prefixes = []  # list to collect prefix data (for list endpoints)
try:
    while url:  # loop to handle pagination; will exit if no further pages or on single object
        response = session.get(url, headers=headers, timeout=5)
        response.raise_for_status()         # raise an error if HTTP request failed (4xx/5xx)
        data = response.json()              # parse response JSON

        if "results" in data:
            # It's a paginated list of objects
            prefixes = data["results"]
            all_prefixes.extend(prefixes)   # accumulate this page's results
            url = data.get("next")          # next page URL (None if this was the last page)
        else:
            # It's a single prefix object (no pagination)
            all_prefixes = [data]           # wrap it in a list for uniformity
            url = None                      # end the loop, no further pages
except requests.exceptions.RequestException as err:
    print(f"Request failed: {err}")
    all_prefixes = []  # empty the result on error (or handle as needed)

# Output the retrieved data in JSON format (pretty-printed)
output_json = json.dumps(all_prefixes, indent=4)
print(output_json)
