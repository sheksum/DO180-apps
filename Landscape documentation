Resolution Steps
1. Confirm NVML Error

nvidia-smi
Output:

Failed to initialize NVML: Driver/library version mismatch
2. Fully Remove Existing NVIDIA Components

sudo apt purge 'nvidia*' 'libnvidia*' 'xserver-xorg-video-nvidia*'
sudo apt autoremove --purge
3. Update Package Index

sudo apt update
4. Reinstall NVIDIA Driver

Temporarily move APT pin if in place:

sudo mv /etc/apt/preferences.d/nvidia-block /root/
Then reinstall:

sudo apt install nvidia-driver-535 nvidia-utils-535
Reapply APT pin after:

sudo mv /root/nvidia-block /etc/apt/preferences.d/
5. Rebuild DKMS Kernel Modules (if needed)

sudo dkms autoinstall
dkms status
Look for:

nvidia/535.230.02, 6.8.0-59-generic, x86_64: installed
6. Reboot

sudo reboot
7. Verify Post-Reboot

nvidia-smi
GPU Support for Docker Containers
8. Install NVIDIA Container Toolkit

sudo apt install -y nvidia-container-toolkit
9. Configure Docker Runtime

sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker
10. Test with CUDA Container

docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi
Let me know if you’d like this in a downloadable format or ready-to-paste markdown for Confluence.

You said:
Title the confluence page
ChatGPT said:
Here’s a complete title and subtitle for your Confluence page:

[RESOLVED] NVIDIA Driver/Library Mismatch & Docker GPU Error on Ubuntu Workstation

AI Workstation (10.172.249.149) – NVML Initialization Failure & Container GPU Runtime Fix
