
# Build Bootstrap Cluster

## Prerequisites

1. You will need an MTLS certificate loaded for SIS in your browser. This will allow you to access the following endpoint from VDE: [https://mtls.sis.tools.vrsn.com](https://mtls.sis.tools.vrsn.com).  
   Refer to the following documentation for [setup](https://wiki.vrsn.com/display/NS/PKI+Client+Onboarding+Steps#PKIClientOnboarding-StepsforinstallingPKIcert).
2. You will need edit privileges for `*.vks.vrsn.com` in SIS. Reach out to the BOS team if you do not yet have access.

## Create SIS profile for bootstrap node

1. Login to [https://mtls.sis.tools.vrsn.com](https://mtls.sis.tools.vrsn.com) with your VCORP credentials (no OTP).
2. Select the `host` schema table.
3. The default bootstrap node in each cluster will be AZ1-HOST1 unless stated otherwise. At a later time once the management cluster is provisioned, AZ1-HOST1 will be utilized as a control plane host for a built cluster.
4. Enter the following search query: `name like "az1%-host1"`.
5. Select the proper host from the search results, e.g. `kdva1-az1-host1.vks.vrsn.com`.
6. Select the `edit` button.
7. Ensure the `build_flag` is checked.
8. Ensure the correct fqdn, hostname, dnsname is set e.g. `kdva1-az1-host1.lab.vks.vrsn.com`.
9. Choose `BUILD_PROFILE` for selecting the latest OS. You can search `name like "<year>-<month><day>"` to find the latest RHEL image that is built daily (e.g. name like `20250227`). Select the RHEL image that starts with UP, e.g. `UP-RHEL9-LATEST` from the example query.
10. Set eth0 interface with MAC address if not already set (IP address, dns_name):
    - a. In eth0 interface section, ensure `mgmt` box is checked.
    - b. Set `mtu` to `1400`.
    - c. Set `name` to `eth0`.
    - d. Look at another bootstrap host for additional clarification such as one in the lab.
11. Set the environment if not already set.
12. `ksmeta=disks=/dev/disk/by-path/pci-0000:3b:00.0-ata-1`

## Build Bootstrap Node

1. Login to the iDRAC of the host. The iDRAC interface for `kdva1-az1-host1.lab.vks.vrsn.com` will be [https://kdva1-az1-host1-oob.lab.vks.vrsn.com](https://kdva1-az1-host1-oob.lab.vks.vrsn.com)
    - a. For the username enter: `obadmin`
    - b. Enter the password for the specific AZ the host belongs to. You can retrieve credentials from a CAPI bootstrap or management cluster:
      ```bash
      kubectl get secrets -n metal3 kdva1-az1-hosts-secret -o json | jq -r .data.password | base64 -d
      ```
2. Start the virtual console once logged in.
3. In the new screen, select `Boot > BIOS Boot Manager`.
4. Select `Power > Power Cycle System (cold boot)`.

### If the host does not PXE properly:

(You will know if it is doing a new Linux installation or not), then perform a restart of the system.

- a. Go into the BIOS.
- b. Change Boot Order to the 25G NIC ("BRCM MBA Port 1") instead of the integrated NIC.
- c. Save changes and exit.

5. You should be able to login to the host once installation is completed. If ssh login is not working:
    - a. Search for the hostname in ServiceNOW.
    - b. Ensure `enable_netboot` is checked under Cobbler and OS.
    - c. Set latest RHEL image under Cobbler and OS.
    - d. Click save.
    - e. Click hamburger icon > `PUSH TO SIS`.

**Note**: If the disk has partition volumes present, the installer may refuse to continue. In that case:
- Open virtual console > press `Alt+F2`.
- Run `lsblk` to find device.
- Run: `wipefs -a /dev/sdX`
- Reboot and reinstall.

## Run Ansible

1. Clone repo: [https://github.vrsn.com/vks/capi-vks-bootstrap-roles](https://github.vrsn.com/vks/capi-vks-bootstrap-roles)
2. Update `inventories.yaml`.
3. Edit group vars and cluster folder/configs.
4. Run playbook per repo instructions.

## Inspection of Bootstrap Cluster Health

1. Get kubeconfig from `/etc/kubernetes/admin.conf`.
2. Set env:
   ```bash
   export KUBECONFIG=cluster-name.conf
   ```
3. Validate Calico BGP:
   ```bash
   k exec -ti calico-node-5w9tg -n calico-system -- bash
   run birdcl
   show protocols
   ```
4. Access Baremetal Operator Ironic API - [docs here](https://github.vrsn.com/vks/vks-docs/blob/main/docs/operations-guide/vks8/baremetal/ironic-api.md)

## Generate and Apply Network Data Resources

1. Clone repo: [https://github.vrsn.com/vks/infra-baremetal](https://github.vrsn.com/vks/infra-baremetal)
2. Checkout new branch:
   ```bash
   git checkout -b VKS-XXX_kva1
   ```
3. Create dir for new region: `infra-baremetal/environments/prod/kva1/`
4. Create subdirs: `inventory`, `network-data`, `switches`
5. Use prior region's file as base and create `inventory.yaml`
6. Update asset info in file.
7. Use script if needed: [generate_switch_network_data.py](https://github.vrsn.com/vks/vks-utils/blob/main/generate_switch_network_data.py)

## Create Baremetal Host Resources

1. Create namespace:
   ```bash
   kubectl create ns kqd2egmgmt-1
   ```
2. Inside inventory dir, create `<region>-oob-secrets.yaml` with one K8s secret per AZ.
3. Do not check in this file to Git.
4. Apply secrets:
   ```bash
   kubectl apply -n <CLUSTER_NAMESPACE> -f <REGION>-oob-secrets.yaml
   ```
5. Create machine resources: `<hostname>-machine.yaml`
   - Copy from existing examples.
6. Run:
   ```bash
   kubectl apply -k .
   kubectl get bmh -A
   ```

## Sample OOB Secrets Manifest

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: kqd2-az1-hosts-secret
  labels:
    clusterctl.cluster.x-k8s.io/move: ""
type: cluster.x-k8s.io/secret
stringData:
  username: USERNAME
  password: PASSWORD
---
apiVersion: v1
kind: Secret
metadata:
  name: kqd2-az2-hosts-secret
  labels:
    clusterctl.cluster.x-k8s.io/move: ""
type: cluster.x-k8s.io/secret
stringData:
  username: USERNAME
  password: PASSWORD
---
apiVersion: v1
kind: Secret
metadata:
  name: kqd2-az3-hosts-secret
  labels:
    clusterctl.cluster.x-k8s.io/move: ""
type: cluster.x-k8s.io/secret
stringData:
  username: USERNAME
  password: PASSWORD
```

## Wipe Storage Devices

```bash
for i in $(openstack baremetal node list --insecure -f value -c name | grep -ie kqd2egmgmt-1); do
  openstack baremetal node clean ${i} --insecure --clean-steps '[{"interface": "deploy", "step": "erase_devices_metadata"}]' --insecure;
done
```
