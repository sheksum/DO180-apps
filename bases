TABNINE UPGRADE PROCEDURE (COPY-FRIENDLY VERSION)

Prerequisites

Ensure kubectl, helm, and yq are installed.

Ensure you have the values file provided directly by Tabnine for this upgrade. Do NOT reuse older values.yaml files.

Ensure you have access to the cluster and namespace (default: tabnine).

Backup Steps (Mandatory Before Upgrade)
A. Backup Kubernetes Secrets
Run:
kubectl get secrets -n tabnine -o yaml > tabnine-secrets-backup-$(date +%F).yaml
chmod 600 tabnine-secrets-backup-$(date +%F).yaml

B. Backup Databases (PostgreSQL + Redis + Non-Evict Redis)
Run the backup script:
chmod +x database_backup.sh
./database_backup.sh tabnine

Ensure the script prints:
“All backups completed successfully”

Do not proceed if backups fail.

Pull New Tabnine Release
Example:
helm pull oci://registry.tabnine.com/self-hosted/tabnine-cloud --version 5.25.1

This downloads:
tabnine-cloud-5.25.1.tgz

Use the Values File Provided by Tabnine
Tabnine will give a file named something like:
tabnine-installations-values-5.25.1.yaml

Run a dry-run:
helm upgrade -f tabnine-installations-values-5.25.1.yaml -n tabnine tabnine tabnine-cloud-5.25.1.tgz --dry-run=server

Perform the Upgrade
If dry-run is clean, run:
helm upgrade -f tabnine-installations-values-5.25.1.yaml -n tabnine tabnine tabnine-cloud-5.25.1.tgz --timeout 1800s

Validate Deployment
kubectl get pods -n tabnine -w

All pods must enter Running state.

GPU Operator Note (If NVIDIA Driver Changed)
If GPU drivers updated, reinstall GPU operator:
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia

helm repo update
helm pull nvidia/gpu-operator --untar
helm install gpu-operator gpu-operator/ -n gpu-operator

Restoration (If Upgrade Fails)
A. Restore Secrets:
kubectl apply -f tabnine-secrets-backup-YYYY-MM-DD.yaml -n tabnine

B. Restore PostgreSQL:
kubectl cp dump.sql tabnine-postgresql-0:/tmp/
kubectl exec -it tabnine-postgresql-0 -- psql -U tabnine -d tabnine -f /tmp/dump.sql

C. Restore Redis Master:
kubectl cp redis.rdb tabnine-redis-master-0:/data/
kubectl exec -it tabnine-redis-master-0 -- redis-cli --rdb /data/redis.rdb

D. Restore Redis Non-Evict:
kubectl cp redis-no-evict.rdb tabnine-no-evict-redis-master-0:/data/
kubectl exec -it tabnine-no-evict-redis-master-0 -- redis-cli --rdb /data/redis-no-evict.rdb

E. Helm Rollback:
helm history tabnine -n tabnine
helm rollback tabnine <REVISION> -n tabnine

Completion Checklist

Secrets backup taken

DB/Redis backups completed

Upgrade executed successfully

All pods running

No CrashLoopBackOff

Indexer and analytics pods healthy

=====================
import json
from collections import defaultdict
from datetime import datetime

# Load the exported JSON file
with open("computers.json") as f:
    computers = json.load(f)

# Group computers by title (hostname)
dupes = defaultdict(list)

for comp in computers:
    title = comp.get("title")
    if not title:
        continue
    last_ping = comp.get("last_ping_time", "")
    try:
        ping_ts = datetime.fromisoformat(last_ping.replace("Z", ""))
    except:
        ping_ts = datetime(1970, 1, 1)
    dupes[title].append((comp["id"], ping_ts))

# Detect duplicates and keep only the most recent
to_delete = []

for title, entries in dupes.items():
    if len(entries) > 1:
        entries.sort(key=lambda x: x[1], reverse=True)
        # Keep most recent, mark others for deletion
        for comp_id, _ in entries[1:]:
            to_delete.append(comp_id)

# Write IDs to file
with open("duplicates_to_delete.txt", "w") as f:
    for comp_id in to_delete:
        f.write(f"{comp_id}\n")

print(f"Done. {len(to_delete)} duplicate computers marked for deletion.")


===========

while read -r id; do
  if [[ -n "$id" ]]; then
    landscape-api remove-computers "$id" \
      --key 4G7C8DEV25ANKFA8YDV1 \
      --secret VMq06pyxKbMN98M1nL4KsKdovuDY6ILK8cUnr8q5 \
      --uri https://10.172.249.104/api/ \
      --ssl-ca-file /etc/ssl/certs/landscape_server.pem
  fi
done < duplicates_to_delete.txt


for db in \
  landscape-standalone-account-1 \
  landscape-standalone-knowledge \
  landscape-standalone-main \
  landscape-standalone-package \
  landscape-standalone-resource-1 \
  landscape-standalone-session
do
  echo "[$db]"
  sudo -u postgres psql -d "$db" -Atc \
  "SELECT tablename FROM pg_tables WHERE schemaname='public' AND (tablename ILIKE '%alert%' OR tablename ILIKE '%event%' OR tablename ILIKE '%notification%');"
done
